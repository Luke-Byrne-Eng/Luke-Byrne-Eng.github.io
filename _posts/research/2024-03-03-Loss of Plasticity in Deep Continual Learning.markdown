---
layout: paper
title:  "Loss of Plasticity in Deep Continual Learning"
date:   18 Aug 2023
categories: research
paper_url: https://arxiv.org/pdf/2306.13812.pdf
code_url: https://github.com/shibhansh/loss-of-plasticity
summary: "Most deep learning systems are designed to be trained once, or possibly pretrained and fintuned. These systems perform quite poorly in continual learning setups where training is ongoing. This is primarily due to two problems: catastrophic forgetting and loss of plasticity. This paper addresses the second. Various architectures and techniques were tested, with L2-regularization and shrink and perturm improving plasticity a little. This paper then introduces Continual Backpropagation, which reinitializes dead units, and seems to maintain plasticity indefinitely "
---

