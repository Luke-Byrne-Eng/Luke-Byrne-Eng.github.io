---
layout: paper
title:  "VideoMamba: State Space Model for Efficient Video Understanding"
date:   12 Mar 2024
categories: research
paper_url: https://arxiv.org/pdf/2403.06977
code_url: 
summary: "This work introduces VideoMamba, an innovative approach that addresses local redundancy and global dependencies in video understanding by adapting the Mamba framework to video analysis. VideoMamba outperforms existing 3D convolutional neural networks and video transformers through its linear-complexity operator, which facilitates efficient long-term modeling for high-resolution, long-duration videos. Its effectiveness is demonstrated across four main areas: scalability in the visual domain without needing extensive dataset pretraining, thanks to a novel self-distillation technique; the ability to recognize short-term actions with fine-grained motion differences; superior performance in long-term video understanding compared to traditional feature-based models; and robust compatibility with multiple modalities, enhancing multi-modal video analysis. VideoMamba establishes a new standard for comprehensive and efficient video understanding."
---

