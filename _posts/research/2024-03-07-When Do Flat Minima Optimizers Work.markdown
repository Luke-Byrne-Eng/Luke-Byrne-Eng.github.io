---
layout: paper
title:  "When Do Flat Minima Optimizers Work?"
date:   27 Jan 2023
categories: research
paper_url: https://arxiv.org/pdf/2202.00661.pdf
code_url: 
summary: "Flat-minima optimizers, including Stochastic Weight Averaging (SWA) and Sharpness-Aware Minimization (SAM), enhance neural network generalization but lack thorough evaluation and cross-domain benchmarking. This study addresses this by comparing their loss surfaces and benchmarking across computer vision, natural language processing, and graph representation learning. The findings offer insights for optimizing deep learning optimizers and choosing suitable ones for specific problems."
---

