---
layout: paper
title:  "Neural Tangent Kernel: Convergence and Generalization in Neural Networks"
date:   10 Feb 2020
categories: research
paper_url: https://arxiv.org/pdf/1806.07572
code_url: 
summary: "This paper demonstrates that artificial neural networks (ANNs) are equivalent to Gaussian processes at initialization in the infinite-width limit and introduces the Neural Tangent Kernel (NTK), which describes ANNs' behavior during training. The NTK stabilizes to a constant in the infinite-width limit, allowing the study of ANNs in function space. The authors prove the positive-definiteness of the limiting NTK under certain conditions and show that the network function follows a linear differential equation during training for least-squares regression. Numerical studies on the NTK in wide networks confirm these theoretical findings."
---

