---
layout: paper
title:  "A Phase Transition between Positional and Semantic Learning in a Solvable Model of Dot-Product Attention"
date:   6 Feb 2024
categories: research
paper_url: https://arxiv.org/pdf/2402.03902.pdf
code_url: 
summary: "We explore the learning process of a dot-product attention layer, which learns both positional and semantic attention matrices, enabling tokens to attend based on position or meaning. Through experiments on an algorithmic task, we demonstrate that this architecture can use either mechanism for solving the task. Theoretically, we examine a non-linear self-attention layer with special query and key matrices, offering a closed-form solution for its non-convex loss landscape in high-dimensional data, which reveals a phase transition from positional to semantic mechanisms as sample complexity increases. We also show that the dot-product attention layer surpasses a linear positional baseline through the semantic mechanism with adequate data."
---

