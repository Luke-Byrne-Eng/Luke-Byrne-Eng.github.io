---
layout: paper
title:  "SGDR: Stochastic Gradient Descent With Warm Restarts"
date:   2 May 2017
categories: research
paper_url: https://arxiv.org/pdf/1608.03983
code_url: 
summary: "This paper introduces a warm restart technique for stochastic gradient descent aimed at enhancing anytime performance in deep neural network training. It showcases empirical performance improvements on CIFAR-10 and CIFAR-100 datasets, achieving state-of-the-art results with 3.14% and 16.21% error rates, respectively. Additionally, the technique's benefits are demonstrated on an EEG dataset and a downsampled ImageNet dataset."
---

