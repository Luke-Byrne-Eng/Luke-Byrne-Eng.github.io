---
layout: paper
title:  "CLIP: Learning Transferable Visual Models From Natural Language Supervision"
date:   26 Feb 2021
categories: research
paper_url: https://arxiv.org/pdf/2103.00020
code_url: 
summary: "This paper introduces a novel approach to computer vision that learns from raw text descriptions of images, moving beyond training on fixed object categories. By pre-training on 400 million (image, text) pairs using caption-image matching, the method achieves state-of-the-art image representations from scratch. This allows for zero-shot transfer to various downstream tasks using natural language, eliminating the need for additional labeled data. The model's performance was evaluated across over 30 diverse datasets, showing competitive results against fully supervised baselines without task-specific training, and matching the accuracy of ResNet-50 on ImageNet zero-shot without using its training examples."
---

