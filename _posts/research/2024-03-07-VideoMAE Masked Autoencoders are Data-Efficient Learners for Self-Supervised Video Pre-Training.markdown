---
layout: paper
title:  "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training"
date:   18 Oct 2022
categories: research
paper_url: https://arxiv.org/pdf/2203.12602.pdf
code_url: 
summary: "The authors introduce VideoMAE, a data-efficient self-supervised video pre-training (SSVP) approach that utilizes video masked autoencoders with a novel high-ratio video tube masking technique inspired by ImageMAE. Key findings include the effectiveness of high masking ratios (90-95%) due to video's temporal redundancy, strong performance on small datasets (~3k-4k videos) without extra data highlighting the importance of high-level structure learning, and data quality being more crucial than quantity with domain shift being significant. Notably, VideoMAE achieves strong performance on several benchmarks using a basic ViT backbone without extra data."
---

