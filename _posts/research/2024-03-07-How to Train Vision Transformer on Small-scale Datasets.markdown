---
layout: paper
title:  "How to Train Vision Transformer on
Small-scale Datasets"
date:   13 Oct 2022
categories: research
paper_url: https://arxiv.org/pdf/2210.07240v1.pdf
code_url: 
summary: "This study demonstrates that self-supervised learning can introduce effective inductive biases directly from small datasets, enabling the fine-tuning of Vision Transformers (ViTs) without relying on large-scale pre-training datasets like ImageNet and JFT or requiring modifications to the architecture or loss functions. The authors show that this approach improves ViT performance on small datasets such as CIFAR10/100, CINIC10, SVHN, Tiny-ImageNet, Aircraft, and Cars, while maintaining ViT's attention to relevant regions and robustness, despite ViT's inherent lack of inductive biases and typical dependence on large-scale pre-training."
---

