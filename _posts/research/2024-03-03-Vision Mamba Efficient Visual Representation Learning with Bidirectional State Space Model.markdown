---
layout: paper
title:  "Vision Mamba: Efficient Visual Representation Learning with Bidirectional
State Space Mode"
date:   10 Feb 2024
categories: research
paper_url: https://arxiv.org/pdf/2401.09417.pdf
code_url: 
summary: "This paper presents Vim, a Vision archetecture that uses bidirectional Mamba blocks, challenging the necessity of self-attention in vision. Testing on ImageNet, COCO, and ADE20k shows Vim outperforms established vision transformers like DeiT in performance while being significantly more computation and memory efficient."
---

