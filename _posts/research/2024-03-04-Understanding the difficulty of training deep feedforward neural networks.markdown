---
layout: paper
title:  "Understanding the difficulty of training deep feedforward neural networks"
date:   31 Mar 2010
categories: research
paper_url: https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf
code_url: 
summary: "This paper introduces Xavier Glorot init for Sigmoid like activation functions. The study investigates the impact of non-linear activation functions, finding the logistic sigmoid activation unsuitable for deep networks due to saturation issues in top hidden layers. It discovers that saturated units can desaturate over time, which explains training plateaus. A new non-linearity that saturates less is suggested as beneficial."
---

