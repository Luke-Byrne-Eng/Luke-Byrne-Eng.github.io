---
layout: paper
title:  "Intriguing Properties of Vision Transformers"
date:   25 Nov 2021
categories: research
paper_url: https://arxiv.org/pdf/2105.10497
code_url: 
summary: "This study investigates how ViT's flexibility in contextual attention aids in overcoming challenges like occlusions, domain shifts, and perturbations in natural images. The authors find ViTs show remarkable resilience to occlusions, perturbations, and domain shifts, maintaining high accuracy even when most of the image is obscured. Unlike CNNs, ViTs exhibit less texture bias, focusing more on shape-based features, which enhances their shape recognition to levels comparable with the human visual system. Additionally, ViTs can perform accurate semantic segmentation without pixel-level supervision and create feature ensembles from a single model for improved classification performance in both traditional and few-shot learning settings. These advantages stem from their dynamic receptive fields enabled by self-attention mechanisms. "
---

