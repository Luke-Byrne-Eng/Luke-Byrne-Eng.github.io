---
layout: paper
title:  "V-Jepa: Latent Video Prediction For Visual Representation Learning"
date:   15 Feb 2023
categories: research
paper_url: https://openreview.net/pdf?id=WFYbBOEOtv
code_url: 
summary: "This paper introduces V-JEPA, a self-supervised video learning method that predicts masked spatio-temporal regions in latent space, effectively applying the masked-modelling principle of large language models to video. This approach generates visual features useful across various image and video tasks without needing model adjustment, achieving significant improvements on Kinetics-400 (82.1%) and Something-Something-v2 (71.2%) benchmarks, outperforming prior video models. V-JEPA also excels in motion understanding tasks, surpassing leading image models like DINOv2 and OpenCLIP, and achieves 77.9% on ImageNet classification with video training alone, setting a new standard for video models."
---

