---
layout: paper
title:  "The geometry of hidden representations of large transformer models"
date:   30 Oct 2023
categories: research
paper_url: https://arxiv.org/pdf/2302.00294.pdf#cite.facco2017id
code_url: 
summary: "This paper investigates the geometric and statistical properties of representations across layers in large transformers used for self-supervised learning on various data types. The authors observe common evolution patterns, with data manifolds expanding initially, contracting at intermediate layers, and the intrinsic dimension (ID) stabilizing or peaking slightly towards the end. They find that semantic information peaks after initial expansion, a trend consistent across models and datasets. The study proposes an unsupervised method to identify layers richest in semantic content, suggesting that those at a relative ID minimum are optimal for downstream tasks."
---

